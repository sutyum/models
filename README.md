# torch-models
Learning by implementing core papers

# Basics
## Generative Models
- [Variational Autoencoder, 2013](https://arxiv.org/abs/1312.6114): With ELBO
- [Masked Autoregressive Flow, 2018](https://arxiv.org/abs/1705.07057)

### Transformer Models
- [GPT2, 2019](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- [ColBERT, 2020](https://arxiv.org/abs/2004.12832)
- [Coconut](https://arxiv.org/pdf/2412.06769), [sample code](https://github.com/lucidrains/coconut-pytorch/blob/main/coconut_pytorch/coconut.py)
- Combine Whisper with Qwen 7b

## Reinforcement Learning
- Reinforce
- [On-policy DPO, Tulu 3](https://arxiv.org/pdf/2411.15124)
- [Reinforcement on Verifiable Reward (RLVR), Tulu 3](https://arxiv.org/pdf/2411.15124)
- [free process rewards without process labels](https://arxiv.org/pdf/2412.01981)

## ICL
- ICLR: [In-context Learning of Representations](https://arxiv.org/pdf/2501.00070)
