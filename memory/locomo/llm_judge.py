"""
LLM-as-Judge DSPy signatures and modules for LOCOMO evaluation.
"""

import dspy
import os
import json
import re
from typing import Dict, Any
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type


class LLMJudgeSignature(dspy.Signature):
    """LLM-as-Judge evaluation following LOCOMO methodology."""

    question: str = dspy.InputField(desc="Original question that was asked")
    ground_truth: str = dspy.InputField(desc="Gold standard answer for comparison")
    generated_answer: str = dspy.InputField(
        desc="Answer generated by the memory system"
    )
    question_category: str = dspy.InputField(
        desc="Category of question (1-5) for category-specific evaluation"
    )

    reasoning: str = dspy.OutputField(
        desc="One sentence explanation of why the answer is correct or incorrect"
    )
    judgment: str = dspy.OutputField(
        desc="CORRECT or WRONG - be generous if the generated answer touches on the same topic as ground truth"
    )


class LOCOMOJudge(dspy.Module):
    """LLM-as-Judge module for LOCOMO evaluation."""

    def __init__(self):
        super().__init__()
        self.judge = dspy.ChainOfThought(LLMJudgeSignature)

    def _parse_judgment(self, judgment_text: str) -> str:
        """Parse and clean judgment text to extract CORRECT/WRONG."""
        if not judgment_text:
            return "WRONG"
        
        # Clean and normalize
        cleaned = judgment_text.strip().upper()
        
        # Direct matches
        if "CORRECT" in cleaned:
            return "CORRECT"
        elif "WRONG" in cleaned:
            return "WRONG"
        
        # Try to extract from JSON-like structures
        try:
            # Look for JSON patterns
            json_match = re.search(r'\{.*\}', judgment_text)
            if json_match:
                json_data = json.loads(json_match.group())
                if 'judgment' in json_data:
                    return json_data['judgment'].upper()
        except:
            pass
        
        # Fallback patterns
        if any(word in cleaned for word in ['YES', 'TRUE', 'ACCEPT', 'PASS']):
            return "CORRECT"
        else:
            return "WRONG"

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=1, max=60),
        retry=retry_if_exception_type((Exception,)),
        retry_error_callback=lambda retry_state: print(f"Retrying judge evaluation after {retry_state.outcome.exception()}")
    )
    def forward(
        self,
        question: str,
        ground_truth: str,
        generated_answer: str,
        question_category: str = "3",
    ) -> dspy.Prediction:
        """Evaluate answer using LLM judge."""
        result = self.judge(
            question=question,
            ground_truth=ground_truth,
            generated_answer=generated_answer,
            question_category=question_category,
        )

        # Parse judgment with fallback
        judgment = self._parse_judgment(result.judgment)
        
        return dspy.Prediction(
            reasoning=getattr(result, 'reasoning', 'No reasoning provided'),
            judgment=judgment,
            is_correct=judgment.upper() == "CORRECT",
        )

    def evaluate_answer(
        self, question: str, ground_truth: str, generated_answer: str
    ) -> Dict[str, Any]:
        """Evaluate answer and return structured result."""
        result = self.forward(question, ground_truth, generated_answer)

        return {
            "judgment": result.judgment,
            "reasoning": result.reasoning,
            "is_correct": result.is_correct,
        }


def create_locomo_judge() -> LOCOMOJudge:
    """Factory function to create LOCOMO LLM judge with OpenAI o4-mini."""
    # Configure OpenAI o4-mini for judging
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        # Use OpenAI o4-mini as the judge
        judge_lm = dspy.LM("o4-mini", api_key=api_key, max_tokens=100_000, temperature=1.0)
        with dspy.context(lm=judge_lm):
            return LOCOMOJudge()
    else:
        # Fallback to current model
        print("WARNING: OPENAI_API_KEY not set, using current model as judge.")
        return LOCOMOJudge()
