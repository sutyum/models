# Quick Screen: BeyondMimic - From motion tracking to versatile humanoid control via guided diffusion

**Authors / Venue / Year:** Qiayuan Liao, ..., C. Karen Liu / Arxiv / Nov 2025
**Link:** https://arxiv.org/pdf/2508.08241

---

## 30-Second Skim (Abstract + Figures)

**What's the claim?** (One line)
Using classifier based guided diffusion can allow for learning and stictching together whole body motions learnt from human motion data.

**The figure that tells the story:** (Figure #)
Figure 7, I dont understand it well

**Task domain:** [ ] Manipulation  [x] Locomotion  [ ] Navigation  [x] Multi-task  [ ] Other: ___

---

## Relevance Filter

| Relevant to... | Yes/No | How? |
|----------------|--------|------|
| VLA / embodied AI |  |  |
| Motor control / low-level |  |  |
| Sim2Real |  |  |
| Data efficiency |  |  |
| My current problem: Motion Tracking | Yes | Whole body agile policies for humanoids |

---

## Quality Signals (Flip through)

- [x] Real robot results (not just sim)
- [ ] Ablations present
- [x] Code released
- [ ] Comparisons to recent (<2 yr) baselines
- [x] Clear failure cases shown

**Red flags spotted:**


---

## Gut Check

**Novelty:** [ ] Incremental  [ ] Solid contribution  [x] Potentially big idea

**Could I explain the core idea right now?** [ ] Yes  [ ] Vaguely  [x] No (complexity signal)

**One thing that made me curious:**
Their results/demos, and their minimal reward setup

---

## Verdict

[x] **DEEP READ** - High relevance, worth 2+ hours
[ ] **SKIM** - Grab the technique, skip details  
[ ] **ARCHIVE** - Reference later if needed
[ ] **SKIP** - Not for me right now

**If reading, focus on Section(s):**
