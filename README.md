# torch-models
Learning by implementing core papers

# Basics
## Graphs
### Essential
- [Graph Convolution Networks, 2016](https://arxiv.org/abs/1609.02907): Node Property Prediction
- [GraphSAGE, 2017](https://arxiv.org/abs/1706.02216): Heterogenous Graphs with Neighbour Sampling
- [Graph Attention Transformer, 2018](https://arxiv.org/abs/1710.10903)

### Reasoning
- [Embedding Logical Queries on Knowledge Graphs, 2019](https://arxiv.org/pdf/1806.01445)
- [Query2Box, 2020](https://arxiv.org/pdf/2002.05969)
> Read: [Traversing Knowledge Graphs in Vector Space, 2015](https://arxiv.org/pdf/1506.01094)

## Generative Models
- [Variational Autoencoder, 2013](https://arxiv.org/abs/1312.6114): With ELBO
- [Masked Autoregressive Flow, 2018](https://arxiv.org/abs/1705.07057)

### Transformer Models
- [GPT2, 2019](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- [ColBERT, 2020](https://arxiv.org/abs/2004.12832)
- [Llama 3.1, 2024](https://ai.meta.com/research/publications/the-llama-3-herd-of-models/): Inference
- [Llama-omni, 2024](https://github.com/sutyum/LLaMA-Omni)
