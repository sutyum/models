"""
LLM-as-Judge DSPy signatures and modules for LOCOMO evaluation.
"""

import dspy
import os
from typing import Dict, Any


class LLMJudgeSignature(dspy.Signature):
    """LLM-as-Judge evaluation following LOCOMO methodology."""

    question: str = dspy.InputField(desc="Original question that was asked")
    ground_truth: str = dspy.InputField(desc="Gold standard answer for comparison")
    generated_answer: str = dspy.InputField(
        desc="Answer generated by the memory system"
    )
    question_category: str = dspy.InputField(
        desc="Category of question (1-5) for category-specific evaluation"
    )

    reasoning: str = dspy.OutputField(
        desc="One sentence explanation of why the answer is correct or incorrect"
    )
    judgment: str = dspy.OutputField(
        desc="CORRECT or WRONG - be generous if the generated answer touches on the same topic as ground truth"
    )


class LOCOMOJudge(dspy.Module):
    """LLM-as-Judge module for LOCOMO evaluation."""

    def __init__(self):
        super().__init__()
        self.judge = dspy.ChainOfThought(LLMJudgeSignature)

    def forward(
        self,
        question: str,
        ground_truth: str,
        generated_answer: str,
        question_category: str = "3",
    ) -> dspy.Prediction:
        """Evaluate answer using LLM judge."""
        result = self.judge(
            question=question,
            ground_truth=ground_truth,
            generated_answer=generated_answer,
            question_category=question_category,
        )

        return dspy.Prediction(
            reasoning=result.reasoning,
            judgment=result.judgment,
            is_correct=result.judgment.upper() == "CORRECT",
        )

    def evaluate_answer(
        self, question: str, ground_truth: str, generated_answer: str
    ) -> Dict[str, Any]:
        """Evaluate answer and return structured result."""
        result = self.forward(question, ground_truth, generated_answer)

        return {
            "judgment": result.judgment,
            "reasoning": result.reasoning,
            "is_correct": result.is_correct,
        }


def create_locomo_judge() -> LOCOMOJudge:
    """Factory function to create LOCOMO LLM judge with OpenAI o4-mini."""
    # Configure OpenAI o4-mini for judging
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        # Use OpenAI o4-mini as the judge
        judge_lm = dspy.LM("o4-mini", api_key=api_key, max_tokens=100_000, temperature=1.0)
        with dspy.context(lm=judge_lm):
            return LOCOMOJudge()
    else:
        # Fallback to current model
        print("WARNING: OPENAI_API_KEY not set, using current model as judge.")
        return LOCOMOJudge()
