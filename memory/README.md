# LOCOMO Memory System - Unified Evaluation Framework

A minimal implementation supporting multiple memory architectures with comprehensive benchmarking using DSPy primitives and LOCOMO LLM judge.

## üéØ Philosophy

- **Minimal**: Use DSPy's built-in capabilities instead of reinventing the wheel
- **Modular**: Common interface for different memory systems
- **Rigorous**: LOCOMO LLM judge for accurate evaluation
- **Fast**: Parallel evaluation with threading

## üöÄ Quick Start

```bash
# Set up environment (choose one)
export TOGETHER_API_KEY="your-together-key"    # For Together AI models
export GROQ_API_KEY="your-groq-key"           # For Groq models

# Compare all systems with different models
./run.sh compare baseline qwen      # Together AI (default)
./run.sh compare baseline llama     # Groq Llama
./run.sh compare baseline mixtral   # Groq Mixtral

# Optimize with fast Groq models
./run.sh optimize simple llama
./run.sh optimize graph gemma

# Direct usage examples  
uv run python main.py compare --model llama --limit 5
uv run python main.py optimize --system graph --model mixtral --limit 20
uv run python main.py evaluate --system simple --model gemma --limit 10
uv run python main.py ask "What did they discuss?" --system baseline --model llama
```

## üèóÔ∏è Memory Systems

| System | Description | Architecture |
|--------|-------------|--------------|
| `baseline` | Direct QA without explicit memory | DSPy ChainOfThought |
| `simple` | Extract-store-retrieve memory | Multi-step DSPy pipeline |
| `graph` | Adaptive memory with ReAct reasoning | Self-evolving memory state |

## ü§ñ Supported Models

| Provider | Model | Key | Best For |
|----------|-------|-----|----------|
| **Together AI** | `qwen` | TOGETHER_API_KEY | Large context, high quality |
| Together AI | `deepseek` | TOGETHER_API_KEY | Code reasoning, analysis |
| **Groq** | `llama` | GROQ_API_KEY | Fast inference, general use |
| Groq | `mixtral` | GROQ_API_KEY | Balanced speed/quality |
| Groq | `gemma` | GROQ_API_KEY | Lightweight, efficient |

## üìÅ Structure

```
memory/
‚îú‚îÄ‚îÄ main.py           # Unified CLI with all functionality
‚îú‚îÄ‚îÄ simple_memory.py  # Extract-retrieve memory system
‚îú‚îÄ‚îÄ graph_memory.py   # Adaptive graph-based memory
‚îú‚îÄ‚îÄ locomo/          # LOCOMO evaluation framework
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py   # Data loading and formatting
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py  # LLM judge metric
‚îÇ   ‚îî‚îÄ‚îÄ llm_judge.py # Judge signatures
‚îî‚îÄ‚îÄ data/            # LOCOMO datasets
```

## üîß Commands

### Core Operations
```bash
# Optimize with fast SIMBA + Groq models
uv run python main.py optimize --system graph --model llama --method simba --threads 8 --limit 50

# Try different model combinations
uv run python main.py optimize --system simple --model mixtral --method bootstrap --limit 30
uv run python main.py optimize --system baseline --model gemma --method mipro --limit 20

# Evaluate with different models
uv run python main.py evaluate --system simple --model llama --limit 20

# Compare all systems across models
uv run python main.py compare --model mixtral --limit 10

# Cross-model benchmarking
uv run python main.py benchmark --model llama --limit 20

# Interactive Q&A with any model
uv run python main.py ask "What was discussed?" --system baseline --model gemma
```

### Quick Scripts
```bash
# Quick comparison with different models
./run.sh compare baseline qwen      # Together AI (default)
./run.sh compare baseline llama     # Groq Llama (faster)

# Complete evaluation pipeline
./run.sh full-eval baseline mixtral  # Full pipeline with Mixtral

# Optimize with fast Groq models
./run.sh optimize graph llama       # Fast optimization
./run.sh optimize simple gemma      # Lightweight model

# Interactive Q&A mode
./run.sh ask baseline llama         # Chat with any model
```

## üìä Evaluation Features

1. **LOCOMO LLM Judge**: Rigorous evaluation following LOCOMO methodology
2. **Comparative Benchmarking**: Test multiple systems simultaneously
3. **Optimization Tracking**: Base vs optimized performance
4. **Parallel Processing**: 8x faster with threading
5. **Detailed Metrics**: Per-category and overall scores

## ‚ö° Performance Optimization

### Fast Optimization with SIMBA
SIMBA is the fastest optimization method with built-in parallelization:

```bash
# Fast parallel optimization (8 threads)
uv run python main.py optimize --method simba --threads 8 --limit 50

# Even faster with fewer steps
uv run python main.py optimize --method simba --threads 16 --limit 30
```

### Optimization Method Comparison
| Method | Speed | Quality | Best For |
|--------|-------|---------|----------|
| `simba` | ‚ö°‚ö°‚ö° Fast | High | Production use |
| `bootstrap` | ‚ö°‚ö° Medium | Medium | Quick prototyping |
| `mipro` | ‚ö° Slow | Highest | Research/best results |

### Threading Guidelines
- **Optimization**: Use 8-16 threads for SIMBA
- **Evaluation**: Use 8 threads (default)
- **Memory**: Graph memory is slowest, baseline fastest

## üí° Key Innovations

1. **Common Interface**: `MemoryInterface` protocol for system interoperability
2. **Adapter Pattern**: Seamless integration of different architectures  
3. **Factory Method**: Clean system instantiation
4. **LOCOMO Integration**: Native support for proper evaluation
5. **DSPy Optimization**: Automatic prompt engineering

## üöÄ Results

Example benchmark showing different memory approaches:

```
System          Base      Optimized  Delta
baseline        45.2%     52.1%      +6.9%
simple          47.8%     55.3%      +7.5%
graph           51.2%     59.7%      +8.5%
```

*Using LOCOMO LLM judge on 50 test examples*

## üîß Usage Notes

### Shell Script Usage
```bash
# Correct - run shell script directly
./run.sh compare

# Incorrect - don't use uv run with shell scripts
# uv run ./run.sh compare  # This will fail
```

### Python Commands
```bash
# Always use uv run for Python commands
uv run python main.py compare --limit 5
uv run python main.py optimize --system simple
```

### Troubleshooting
1. **Permission Error**: `chmod +x run.sh`
2. **Missing Dependencies**: `uv add dspy-ai click`
3. **API Keys**: Set `TOGETHER_API_KEY` or `GROQ_API_KEY`
4. **Data Files**: Ensure `data/locomo_*.json` files exist
5. **Model Selection**: Use `--model` flag or third script argument

### Environment Setup
```bash
# Option 1: Together AI (high quality)
export TOGETHER_API_KEY="your-together-ai-key"

# Option 2: Groq (fast inference)  
export GROQ_API_KEY="your-groq-key"

# Option 3: Both (flexibility)
export TOGETHER_API_KEY="your-together-key"
export GROQ_API_KEY="your-groq-key"

# Install dependencies
uv add dspy-ai click

# Verify with different models
uv run python main.py --help

# Quick functionality test
uv run python main.py ask "What did they discuss?" --conversation "Alice: Hi Bob! Bob: Hello Alice!"

# Full comparison test
uv run python main.py compare --limit 2   # Test with default model
```
